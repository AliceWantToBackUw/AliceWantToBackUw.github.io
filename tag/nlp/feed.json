{
    "version": "https://jsonfeed.org/version/1",
    "title": "Hexo • All posts by \"nlp\" tag",
    "description": "",
    "home_page_url": "https://alicewanttobackuw.github.io",
    "items": [
        {
            "id": "https://alicewanttobackuw.github.io/2023/01/29/%E5%8C%BB%E7%96%97%E8%AF%8A%E6%96%AD%E6%96%87%E6%9C%AC%E5%A4%9A%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98%EF%BC%88NLP)%EF%BC%88%E5%90%88%E5%B7%A5%E5%A4%A7%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%89/",
            "url": "https://alicewanttobackuw.github.io/2023/01/29/%E5%8C%BB%E7%96%97%E8%AF%8A%E6%96%AD%E6%96%87%E6%9C%AC%E5%A4%9A%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98%EF%BC%88NLP)%EF%BC%88%E5%90%88%E5%B7%A5%E5%A4%A7%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%89/",
            "title": "🤖医疗诊断文本多分类问题（NLP)（合工大机器学习）",
            "date_published": "2023-01-29T07:12:11.000Z",
            "content_html": "<p><img data-src=\"https://cdn.statically.io/gh/AliceWantToBackUw/blog-img@main/PicGo/202301291523489.png\" alt=\"image-20230129152257115\" /></p>\n<h1 id=\"欢迎各位友友来-我后院建设中-里踩踩\"><a class=\"anchor\" href=\"#欢迎各位友友来-我后院建设中-里踩踩\">#</a> 🍭🍭欢迎各位友友来 <a href=\"https://alicewanttobackuw.github.io/\">我后院 (建设中)</a> 里踩踩🍭🍭</h1>\n<blockquote>\n<p>📢 声明：<br />\n转载，请先标注出处哦！编写不易，尊重一下劳动成果哦！<br />\n个人博客网站 \t==》<a href=\"https://alicewanttobackuw.github.io/\">https://alicewanttobackuw.github.io/</a><br />\ngithub\t==》<span class=\"exturl\" data-url=\"aHR0cHM6Ly9naXRodWIuY29tL0FsaWNlV2FudFRvQmFja1V3\">https://github.com/AliceWantToBackUw</span><br />\ncsdn\t==》<span class=\"exturl\" data-url=\"aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xlbmd5dWUyOQ==\">https://blog.csdn.net/lengyue29</span></p>\n</blockquote>\n<blockquote>\n<p>📢 <strong>更新说明</strong>：2024-02-18 14:55:10<br />\n 由于用于 cdn 加速的 <code>staticaly.com</code>  域名过期，移至新域名 <code>statically.io</code> ，导致图片无法加载，现已修复</p>\n</blockquote>\n<hr />\n<h1 id=\"医疗诊断文本多分类问题nlp合工大机器学习\"><a class=\"anchor\" href=\"#医疗诊断文本多分类问题nlp合工大机器学习\">#</a> 🤖医疗诊断文本多分类问题（NLP)（合工大机器学习）</h1>\n<h2 id=\"说明\"><a class=\"anchor\" href=\"#说明\">#</a> 📢 说明</h2>\n<p>​\t 完整代码和相关资源在<span class=\"exturl\" data-url=\"aHR0cHM6Ly9naXRodWIuY29tL0FsaWNlV2FudFRvQmFja1V3L01lZGljYWwtRGlhZ25vc3RpYy1UZXh0LUNsYXNzaWZpY2F0aW9uLU5MUC0=\">本人 github</span> 上。（论文就不放了哈，史老师应该教了你们怎么写）</p>\n<h2 id=\"问题引入\"><a class=\"anchor\" href=\"#问题引入\">#</a> ❓ 问题引入</h2>\n<p>​\t附件 <code>gastric.xlsx</code>  是包含 <code>5</code>  类的病理诊断文本报告数据集，请完成以下任务：（1）使用 <code>1</code>  种<strong>非深度学习算法</strong>和至少 <code>2</code>  种<strong>深度学习算法</strong>完成文本分类，介绍算法原理并评估算法性能；<br />\n​\t先检查附件，共 <code>250</code>  条数据，并且<strong>高度相关</strong></p>\n<p><img data-src=\"https://cdn.statically.io/gh/AliceWantToBackUw/blog-img@main/PicGo/202301291536046.png\" alt=\"image-20230129153410497\" /></p>\n<h2 id=\"方法决策\"><a class=\"anchor\" href=\"#方法决策\">#</a> 🧠方法决策</h2>\n<p>​\t对于<strong>自然语言文本分类</strong>问题的处理的常用算法有很多。<br />\n​\t<strong>非深度学习算法</strong>： <code>K-近邻算法</code> 、 <code>朴素贝叶斯算法</code> 、 <code>决策树</code> 以及 <code>集成学习方法之随机森林</code> 等。<br />\n​\t<strong>深度学习算法</strong>： <code>TextCNN</code> 、 <code>FastText</code> 、 <code>DPCNN</code> 、 <code>TextRNN</code> 、 <code>TextRCNN</code>  以及 <code>Bert</code>  等。</p>\n<p>​\t本题中，非深度学习算法，我采用随机森林算法；深度学习算法，我采用 TextCNN 和 FaxtText。</p>\n<h3 id=\"传统机器学习方法中\"><a class=\"anchor\" href=\"#传统机器学习方法中\">#</a> ⚙传统机器学习方法中：</h3>\n<ul>\n<li><code>K-近邻算法</code> ，虽然简单，易于理解，易于实现，还无需训练，但缺点很明显，它是一种懒惰算法，对测试样本分类时的计算量大，内存开销大，而且还需要手动指定 K 值， K 值选择不当则分类精度不能保证。</li>\n<li><code>朴素贝叶斯算法</code> ，虽然也比较简单，分类准确的较高，速度还比较快，但却有个较大的缺点，该算法由于使用了样本属性独立性的假设，所以如果特征属性有关联时其效果不好。由于我需要处理的是医疗诊断文本，其中有很多专业词是高度关联的，因此也不太适合。</li>\n<li><code>决策树</code> ，通过信息增益等方法来进行作为分类依据，它的效果就明显，准确率高，不过最大的缺点就是，容易出过拟合。</li>\n<li><code>随机森林算法</code> ，控制森林的高度和森林中树木的数量，确保准确率的同时有效防止过拟合。由于森林的高度和树木的数量属于超参数，所以我再加上一个网格搜索，实现自动调参，选择最合适的超参数，作为模型。</li>\n</ul>\n<p>​\t因此我选择采用 <code>随机森林算法</code></p>\n<h3 id=\"深度学习方法中\"><a class=\"anchor\" href=\"#深度学习方法中\">#</a> ⚙深度学习方法中：</h3>\n<ul>\n<li><code>TextCNN</code> ，一听到 CNN 就会联想到图像处理邻域。而 TextCNN 创新之处就在于，通过将卷积神经网络 CNN 应用到文本分类任务中，利用多个不同 size 的 kernel 来提取句子中的关键信息。从而能够更好地捕捉局部相关性。与传统图像的 CNN 网络相比，textCNN 在网络结构上没有任何变化 (甚至更加简单了)。虽然 TextCNN 网络结构简单，但在模型网络结构如此简单的情况下，通过引入已经训练好的词向量依旧有很不错的效果，在多项数据数据集上超越 benchmark。所以，我选用了 TextCNN 算法。</li>\n<li><code>FastText</code> ，FastText 是 Facebook 于 2016 年开源的一个词向量计算和文本分类工具，在学术上并没有太大创新。但是它的优点也非常明显，在文本分类任务中，FastText（浅层网络）往往能取得和深度网络相媲美的精度，却在训练时间上比深度网络快许多数量级。在标准的多核 CPU 上， 能够训练 10 亿词级别语料库的词向量在 10 分钟之内，能够分类有着 30 万多类别的 50 多万句子在 1 分钟之内。FastText 的核心思想： 将整篇文档的词及 n-gram 向量叠加平均得到文档向量，然后使用文档向量做 softmax 多分类。这中间涉及到两个技巧：字符级 n-gram 特征的引入以及分层 Softmax 分类。而且，官网给的文档还有指定时间自动调优的方法，所以我选用了 FastText 算法。</li>\n</ul>\n<blockquote>\n<p>📕参考自黑马讲义文档：<br />\n<span class=\"exturl\" data-url=\"aHR0cHM6Ly93d3cuYWxpeXVuZHJpdmUuY29tL3MvUlNhVGFZOGpLeW4=\">阿里云盘：密码 6h3j</span></p>\n</blockquote>\n<h2 id=\"开始实战\"><a class=\"anchor\" href=\"#开始实战\">#</a> 🥊开始实战</h2>\n<h3 id=\"随机森林算法\"><a class=\"anchor\" href=\"#随机森林算法\">#</a> 🔑随机森林算法</h3>\n<ul>\n<li>\n<p>最开始导包</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">import</span> pandas <span class=\"token keyword\">as</span> pd</pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token keyword\">import</span> jieba <span class=\"token keyword\">as</span> jb</pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>feature_extraction<span class=\"token punctuation\">.</span>text <span class=\"token keyword\">import</span> TfidfVectorizer</pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>decomposition <span class=\"token keyword\">import</span> PCA</pre></td></tr><tr><td data-num=\"5\"></td><td><pre><span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>model_selection <span class=\"token keyword\">import</span> train_test_split</pre></td></tr><tr><td data-num=\"6\"></td><td><pre><span class=\"token keyword\">import</span> matplotlib<span class=\"token punctuation\">.</span>pyplot <span class=\"token keyword\">as</span> plt</pre></td></tr><tr><td data-num=\"7\"></td><td><pre><span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>ensemble <span class=\"token keyword\">import</span> RandomForestClassifier</pre></td></tr><tr><td data-num=\"8\"></td><td><pre><span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>model_selection <span class=\"token keyword\">import</span> GridSearchCV</pre></td></tr><tr><td data-num=\"9\"></td><td><pre><span class=\"token keyword\">import</span> joblib</pre></td></tr></table></figure></li>\n<li>\n<p>首先，获取数据，加载停用词（注意：读取 <code>.xlsx文件</code> 需要指定 <code>openpyxl</code> ）</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\"># 1、获取数据</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>all_pd_data <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>read_excel<span class=\"token punctuation\">(</span>io<span class=\"token operator\">=</span><span class=\"token string\">\"../src/gastric.xlsx\"</span><span class=\"token punctuation\">,</span> engine<span class=\"token operator\">=</span><span class=\"token string\">\"openpyxl\"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre></pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token comment\">#   * 加载停用词</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre><span class=\"token keyword\">with</span> <span class=\"token builtin\">open</span><span class=\"token punctuation\">(</span><span class=\"token string\">'../src/stop_words.txt'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'r'</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>          encoding<span class=\"token operator\">=</span><span class=\"token string\">\"utf-8\"</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> f<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>    stop_words <span class=\"token operator\">=</span> <span class=\"token builtin\">list</span><span class=\"token punctuation\">(</span>l<span class=\"token punctuation\">.</span>strip<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> l <span class=\"token keyword\">in</span> f<span class=\"token punctuation\">.</span>readlines<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre><span class=\"token comment\"># 由于停用词中没有 '\\n' 和中文的左右括号和空格，所以单独再加上去</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre>stop_words<span class=\"token punctuation\">.</span>extend<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token string\">'\\n'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'（'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'）'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">' '</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure></li>\n<li>\n<p>其次，对数据进行预处理，对中文文本进行分词，<strong>随机</strong>划分训练集和测试集（注意：按照 <code>Label</code> <strong> 分层抽样</strong>，确保训练集和测试集样本<strong>均匀</strong>）</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\"># 2、数据预处理</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token comment\">#   * 对中文文本进行分词</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>all_pd_data<span class=\"token punctuation\">[</span><span class=\"token string\">'Pre_Text'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> all_pd_data<span class=\"token punctuation\">[</span><span class=\"token string\">'Text'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">apply</span><span class=\"token punctuation\">(</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>    <span class=\"token keyword\">lambda</span> x<span class=\"token punctuation\">:</span> <span class=\"token string\">\" \"</span><span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>w <span class=\"token keyword\">for</span> w <span class=\"token keyword\">in</span> <span class=\"token builtin\">list</span><span class=\"token punctuation\">(</span>jb<span class=\"token punctuation\">.</span>cut<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">if</span> w <span class=\"token keyword\">not</span> <span class=\"token keyword\">in</span> stop_words<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre></pre></td></tr><tr><td data-num=\"6\"></td><td><pre><span class=\"token comment\">#   * 划分训练集和测试集 （按照 Label 采用分层抽样，保证训练集和测试集样本均匀）</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>file_txt_train<span class=\"token punctuation\">,</span> file_txt_test <span class=\"token operator\">=</span> train_test_split<span class=\"token punctuation\">(</span>all_pd_data<span class=\"token punctuation\">,</span> test_size<span class=\"token operator\">=</span><span class=\"token number\">0.2</span><span class=\"token punctuation\">,</span> stratify<span class=\"token operator\">=</span>all_pd_data<span class=\"token punctuation\">[</span><span class=\"token string\">'Label'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure></li>\n<li>\n<p>然后，进行<strong>特征工程</strong>，使用 <code>tf-idf</code>  进行提取特征，再通过 <code>PCA</code>  进行降维，剔除相关性较大的特征</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\"># 3、特征工程</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token comment\">#   * 3.1、求出训练集 tf-idf</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token comment\">#   *   3.1.1、实例化一个转换器类</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>transfer <span class=\"token operator\">=</span> TfidfVectorizer<span class=\"token punctuation\">(</span>stop_words<span class=\"token operator\">=</span>stop_words<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre><span class=\"token comment\">#   *   3.1.2、调用 fit_transform</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>x_train <span class=\"token operator\">=</span> transfer<span class=\"token punctuation\">.</span>fit_transform<span class=\"token punctuation\">(</span>file_txt_train<span class=\"token punctuation\">[</span><span class=\"token string\">\"Pre_Text\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>x_test <span class=\"token operator\">=</span> transfer<span class=\"token punctuation\">.</span>transform<span class=\"token punctuation\">(</span>file_txt_test<span class=\"token punctuation\">[</span><span class=\"token string\">\"Pre_Text\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre>x_train_feature <span class=\"token operator\">=</span> transfer<span class=\"token punctuation\">.</span>get_feature_names<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre>x_train <span class=\"token operator\">=</span> x_train<span class=\"token punctuation\">.</span>toarray<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre>x_test <span class=\"token operator\">=</span> x_test<span class=\"token punctuation\">.</span>toarray<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre>y_train <span class=\"token operator\">=</span> file_txt_train<span class=\"token punctuation\">[</span><span class=\"token string\">\"Label\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>tolist<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"12\"></td><td><pre>y_test <span class=\"token operator\">=</span> file_txt_test<span class=\"token punctuation\">[</span><span class=\"token string\">\"Label\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>tolist<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"13\"></td><td><pre><span class=\"token comment\"># print (\"文本特征抽取的结果：\\n\", x_train.toarray ())</span></pre></td></tr><tr><td data-num=\"14\"></td><td><pre><span class=\"token comment\"># print (\"返回特征名字：\\n\", transfer.get_feature_names ())</span></pre></td></tr><tr><td data-num=\"15\"></td><td><pre></pre></td></tr><tr><td data-num=\"16\"></td><td><pre><span class=\"token comment\">#   * 3.2、通过 PCA 降维</span></pre></td></tr><tr><td data-num=\"17\"></td><td><pre><span class=\"token comment\">#   *   3.2.1、实例化一个转换器类 PCA</span></pre></td></tr><tr><td data-num=\"18\"></td><td><pre>transfer <span class=\"token operator\">=</span> PCA<span class=\"token punctuation\">(</span>n_components<span class=\"token operator\">=</span><span class=\"token number\">80</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"19\"></td><td><pre><span class=\"token comment\">#   *   3.2.1、调用 fit_transform</span></pre></td></tr><tr><td data-num=\"20\"></td><td><pre>x_train <span class=\"token operator\">=</span> transfer<span class=\"token punctuation\">.</span>fit_transform<span class=\"token punctuation\">(</span>x_train<span class=\"token punctuation\">,</span> x_train_feature<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"21\"></td><td><pre>x_test <span class=\"token operator\">=</span> transfer<span class=\"token punctuation\">.</span>transform<span class=\"token punctuation\">(</span>x_test<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"22\"></td><td><pre><span class=\"token comment\">#   * 3.3、准备超参数</span></pre></td></tr><tr><td data-num=\"23\"></td><td><pre>param_grid <span class=\"token operator\">=</span> <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"24\"></td><td><pre>    <span class=\"token string\">\"n_estimators\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">[</span><span class=\"token number\">100</span><span class=\"token punctuation\">,</span> <span class=\"token number\">200</span><span class=\"token punctuation\">,</span> <span class=\"token number\">300</span><span class=\"token punctuation\">,</span> <span class=\"token number\">400</span><span class=\"token punctuation\">,</span> <span class=\"token number\">500</span><span class=\"token punctuation\">,</span> <span class=\"token number\">600</span><span class=\"token punctuation\">,</span> <span class=\"token number\">700</span><span class=\"token punctuation\">,</span> <span class=\"token number\">800</span><span class=\"token punctuation\">,</span> <span class=\"token number\">900</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1000</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"25\"></td><td><pre>    <span class=\"token string\">\"max_depth\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">[</span><span class=\"token number\">5</span><span class=\"token punctuation\">,</span> <span class=\"token number\">8</span><span class=\"token punctuation\">,</span> <span class=\"token number\">15</span><span class=\"token punctuation\">,</span> <span class=\"token number\">25</span><span class=\"token punctuation\">,</span> <span class=\"token number\">30</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"26\"></td><td><pre><span class=\"token punctuation\">&#125;</span></pre></td></tr><tr><td data-num=\"27\"></td><td><pre><span class=\"token comment\"># x_train.shape  # (200, 80)</span></pre></td></tr></table></figure></li>\n<li>\n<p>接着，构建随机森林模型。 <code>cv</code>  的次数自己根据电脑情况调节。</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\"># 4、构建随机森林模型</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>estimator <span class=\"token operator\">=</span> RandomForestClassifier<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>estimator <span class=\"token operator\">=</span> GridSearchCV<span class=\"token punctuation\">(</span>estimator<span class=\"token operator\">=</span>estimator<span class=\"token punctuation\">,</span> param_grid<span class=\"token operator\">=</span>param_grid<span class=\"token punctuation\">,</span> cv<span class=\"token operator\">=</span><span class=\"token number\">3</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token comment\"># 开始训练</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>estimator<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>x_train<span class=\"token punctuation\">,</span> y_train<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre><span class=\"token comment\">#   * 保存模型</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>joblib<span class=\"token punctuation\">.</span>dump<span class=\"token punctuation\">(</span>estimator<span class=\"token punctuation\">,</span> <span class=\"token string\">\"./随机森林模型.pkl\"</span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure></li>\n<li>\n<p>最后，加载模型并通过绘图评估模型</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\"># 5、评估模型</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token comment\">#   * 加载模型</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>estimator <span class=\"token operator\">=</span> joblib<span class=\"token punctuation\">.</span>load<span class=\"token punctuation\">(</span><span class=\"token string\">\"./随机森林模型.pkl\"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token comment\">#   * 进行预测</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>y_predict <span class=\"token operator\">=</span> estimator<span class=\"token punctuation\">.</span>predict<span class=\"token punctuation\">(</span>x_test<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre><span class=\"token comment\"># 计算准确率</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>score <span class=\"token operator\">=</span> estimator<span class=\"token punctuation\">.</span>score<span class=\"token punctuation\">(</span>x_test<span class=\"token punctuation\">,</span> y_test<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre><span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"准确率：\\n\"</span><span class=\"token punctuation\">,</span> score<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre></pre></td></tr><tr><td data-num=\"10\"></td><td><pre><span class=\"token comment\"># 查看最佳参数，最佳结果，最佳估计器</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre><span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"查看最佳参数:\\n\"</span><span class=\"token punctuation\">,</span> estimator<span class=\"token punctuation\">.</span>best_params_<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"12\"></td><td><pre><span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"最佳结果：\\n\"</span><span class=\"token punctuation\">,</span> estimator<span class=\"token punctuation\">.</span>best_score_<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"13\"></td><td><pre></pre></td></tr><tr><td data-num=\"14\"></td><td><pre><span class=\"token comment\">#   * 绘图</span></pre></td></tr><tr><td data-num=\"15\"></td><td><pre>results <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>DataFrame<span class=\"token punctuation\">(</span>estimator<span class=\"token punctuation\">.</span>cv_results_<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"16\"></td><td><pre>plt<span class=\"token punctuation\">.</span>rcParams<span class=\"token punctuation\">[</span><span class=\"token string\">\"font.sans-serif\"</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"SimHei\"</span><span class=\"token punctuation\">]</span>  <span class=\"token comment\"># 显示中文标签</span></pre></td></tr><tr><td data-num=\"17\"></td><td><pre>plt<span class=\"token punctuation\">.</span>figure<span class=\"token punctuation\">(</span>figsize<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">15</span><span class=\"token punctuation\">,</span> <span class=\"token number\">6</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"18\"></td><td><pre>plt<span class=\"token punctuation\">.</span>subplot<span class=\"token punctuation\">(</span><span class=\"token number\">121</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"19\"></td><td><pre>plt<span class=\"token punctuation\">.</span>xlabel<span class=\"token punctuation\">(</span><span class=\"token string\">'n_estimators'</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"20\"></td><td><pre>plt<span class=\"token punctuation\">.</span>ylabel<span class=\"token punctuation\">(</span><span class=\"token string\">'mean_test_score'</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"21\"></td><td><pre>each_length <span class=\"token operator\">=</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>param_grid<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">\"n_estimators\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 每次森林树木数量的种类</span></pre></td></tr><tr><td data-num=\"22\"></td><td><pre><span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>param_grid<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">\"max_depth\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"23\"></td><td><pre>    plt<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span>param_grid<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">\"n_estimators\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> results<span class=\"token punctuation\">[</span><span class=\"token string\">\"mean_test_score\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>tolist<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span>i <span class=\"token operator\">*</span> each_length<span class=\"token punctuation\">:</span><span class=\"token punctuation\">(</span>i <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">*</span> each_length<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"24\"></td><td><pre>             label<span class=\"token operator\">=</span><span class=\"token string\">\"max_depth:  \"</span> <span class=\"token operator\">+</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">(</span>param_grid<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">\"max_depth\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"25\"></td><td><pre>plt<span class=\"token punctuation\">.</span>legend<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"26\"></td><td><pre></pre></td></tr><tr><td data-num=\"27\"></td><td><pre>plt<span class=\"token punctuation\">.</span>subplot<span class=\"token punctuation\">(</span><span class=\"token number\">122</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"28\"></td><td><pre>scale_ls <span class=\"token operator\">=</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">6</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"29\"></td><td><pre>plt<span class=\"token punctuation\">.</span>title<span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"best_params: \\n\"</span></span></pre></td></tr><tr><td data-num=\"30\"></td><td><pre>          <span class=\"token string-interpolation\"><span class=\"token string\">f\"max_depth: </span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span>estimator<span class=\"token punctuation\">.</span>best_params_<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">'max_depth'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">&#125;</span></span><span class=\"token string\">  \"</span></span></pre></td></tr><tr><td data-num=\"31\"></td><td><pre>          <span class=\"token string-interpolation\"><span class=\"token string\">f\"n_estimators: </span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span>estimator<span class=\"token punctuation\">.</span>best_params_<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">'n_estimators'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">&#125;</span></span><span class=\"token string\">\\n\"</span></span></pre></td></tr><tr><td data-num=\"32\"></td><td><pre>          <span class=\"token string-interpolation\"><span class=\"token string\">f\"acc: </span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span>score<span class=\"token punctuation\">&#125;</span></span><span class=\"token string\">\"</span></span><span class=\"token punctuation\">,</span> fontsize<span class=\"token operator\">=</span><span class=\"token number\">20</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"33\"></td><td><pre>index_ls <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token string\">'__label__1'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'__label__2'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'__label__3'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'__label__4'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'__label__5'</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"34\"></td><td><pre>plt<span class=\"token punctuation\">.</span>yticks<span class=\"token punctuation\">(</span>scale_ls<span class=\"token punctuation\">,</span> index_ls<span class=\"token punctuation\">)</span>  <span class=\"token comment\">## 可以设置坐标字</span></pre></td></tr><tr><td data-num=\"35\"></td><td><pre>plt<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span>y_test<span class=\"token punctuation\">,</span> color<span class=\"token operator\">=</span><span class=\"token string\">\"red\"</span><span class=\"token punctuation\">,</span> marker<span class=\"token operator\">=</span><span class=\"token string\">'o'</span><span class=\"token punctuation\">,</span> label<span class=\"token operator\">=</span><span class=\"token string\">\"真实分类\"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"36\"></td><td><pre>plt<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span>y_predict<span class=\"token punctuation\">,</span> color<span class=\"token operator\">=</span><span class=\"token string\">\"blue\"</span><span class=\"token punctuation\">,</span> marker<span class=\"token operator\">=</span><span class=\"token string\">'.'</span><span class=\"token punctuation\">,</span> label<span class=\"token operator\">=</span><span class=\"token string\">\"预测分类\"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"37\"></td><td><pre>plt<span class=\"token punctuation\">.</span>xlabel<span class=\"token punctuation\">(</span><span class=\"token string\">\"样本\"</span><span class=\"token punctuation\">,</span> fontsize<span class=\"token operator\">=</span><span class=\"token number\">14</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"38\"></td><td><pre>plt<span class=\"token punctuation\">.</span>ylabel<span class=\"token punctuation\">(</span><span class=\"token string\">\"分类\"</span><span class=\"token punctuation\">,</span> fontsize<span class=\"token operator\">=</span><span class=\"token number\">14</span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure></li>\n</ul>\n<p><img data-src=\"https://cdn.statically.io/gh/AliceWantToBackUw/blog-img@main/PicGo/202301291603149.png\" alt=\"image-20230129160341007\" /></p>\n<p>​\t从图中可以看出，在<strong>测试集</strong>上的 <code>准确率：0.76</code> 。<br />\n​\t此时模型最优的模型参数是，<strong>森林的最大高度：</strong> <code>8</code> ；<strong>森林的树木数量：</strong> <code>400</code> <br />\n​\t而且，经过多次运行，发现测试集上的准确率并不稳定，浮动较大。怎么说咧，结果还是差强人意。不过，毕竟只有 <code>250</code>  条数据，使用非深度学习方法能达到这样，还行。</p>\n<h3 id=\"textcnn\"><a class=\"anchor\" href=\"#textcnn\">#</a> 🔑TextCNN</h3>\n<blockquote>\n<p>** 前提：** 本算法使用了 <code>tensorflow-gpu</code> ，配置好了 <code>GPU</code> <br />\n<strong>tensorflow 学习视频：</strong><span class=\"exturl\" data-url=\"aHR0cHM6Ly93d3cuaWNvdXJzZTE2My5vcmcvY291cnNlL1hVU1QtMTIwNjM2MzgwMj90aWQ9MTQ2ODcwNzU3MA==\">神经网络与深度学习 —TensorFlow 实践_中国大学 MOOC (慕课)</span></p>\n</blockquote>\n<ul>\n<li>\n<p>同样首先，导包</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">import</span> pandas <span class=\"token keyword\">as</span> pd</pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token keyword\">import</span> jieba <span class=\"token keyword\">as</span> jb</pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token keyword\">import</span> tensorflow <span class=\"token keyword\">as</span> tf</pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token keyword\">import</span> matplotlib<span class=\"token punctuation\">.</span>pyplot <span class=\"token keyword\">as</span> plt</pre></td></tr><tr><td data-num=\"5\"></td><td><pre><span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>model_selection <span class=\"token keyword\">import</span> train_test_split</pre></td></tr></table></figure></li>\n<li>\n<p>接着，同样先获取数据，设置一下 <code>GPU</code> ，并按照 <code>Label</code>  采用分层随机抽样</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\"># 1、获取数据</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>excel <span class=\"token operator\">=</span> <span class=\"token string\">'../src/gastric.xlsx'</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token comment\"># 使用 pandas 读取 excel 数据，需要指定 engine 为 openpyxl（需先要下载 openpyxl）</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>file_txt <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>read_excel<span class=\"token punctuation\">(</span>excel<span class=\"token punctuation\">,</span> engine<span class=\"token operator\">=</span><span class=\"token string\">\"openpyxl\"</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\">#[250 rows x 2 columns]</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre><span class=\"token comment\"># * 配置 GPU</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre><span class=\"token comment\"># 打印 tensorflow 版本信息  # 2.10.0   2.10.0</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre><span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>__version__<span class=\"token punctuation\">,</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>__version__<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre><span class=\"token comment\"># 获取 gpu</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre>gpus <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>config<span class=\"token punctuation\">.</span>experimental<span class=\"token punctuation\">.</span>list_physical_devices<span class=\"token punctuation\">(</span><span class=\"token string\">'GPU'</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre><span class=\"token comment\"># 允许 gpu 内存增长（我只有一个 GPU, 多个 GPU 使用循环配置）</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre>tf<span class=\"token punctuation\">.</span>config<span class=\"token punctuation\">.</span>experimental<span class=\"token punctuation\">.</span>set_memory_growth<span class=\"token punctuation\">(</span>gpus<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"12\"></td><td><pre></pre></td></tr><tr><td data-num=\"13\"></td><td><pre><span class=\"token comment\">#   1.2、划分训练集和测试集（按照 Label 采用分层抽样，保证训练集和测试集样本均匀）</span></pre></td></tr><tr><td data-num=\"14\"></td><td><pre>file_txt_train<span class=\"token punctuation\">,</span> file_txt_test <span class=\"token operator\">=</span> train_test_split<span class=\"token punctuation\">(</span>file_txt<span class=\"token punctuation\">,</span> test_size<span class=\"token operator\">=</span><span class=\"token number\">0.2</span><span class=\"token punctuation\">,</span> stratify<span class=\"token operator\">=</span>file_txt<span class=\"token punctuation\">[</span><span class=\"token string\">'Label'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure></li>\n<li>\n<p>然后，对文本进行预处理。先加载停用词，分词，接着将词映射为整数。<br />\n** 映射为整数的思路：** 先把每一个样本分词，取分词最多的样本的词数量作为最大的词长度，对没有达到的样本，进行末端补 <code>0</code>  操作（因为输入卷积模型的词向量的长度需要保持一致）<br />\n获取 <code>tokenizer</code>  尤其注意，需要加一个未知词 <code>&lt;UNK&gt;</code> 。<br />\n还需要注意：使用 <code>num_class</code> ，标签值中的 <code>最大数加1</code></p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\"># 2、对 text 文本进行预处理</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token comment\">#   2.1、加载停用词</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token keyword\">with</span> <span class=\"token builtin\">open</span><span class=\"token punctuation\">(</span><span class=\"token string\">'../src/stop_words.txt'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'r'</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>          encoding<span class=\"token operator\">=</span><span class=\"token string\">\"utf-8\"</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> f<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>    stop_words <span class=\"token operator\">=</span> <span class=\"token builtin\">list</span><span class=\"token punctuation\">(</span>l<span class=\"token punctuation\">.</span>strip<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> l <span class=\"token keyword\">in</span> f<span class=\"token punctuation\">.</span>readlines<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>stop_words<span class=\"token punctuation\">.</span>extend<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token string\">'\\n'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'（'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'）'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">' '</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 由于停用词中没有 '\\n' 和中文的左右括号和空格，所以单独再加上去</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre><span class=\"token comment\">#   2.2、对训练集和测试集分词，并去除停用词</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre>file_txt_train<span class=\"token punctuation\">[</span><span class=\"token string\">'Pre_Text'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> file_txt_train<span class=\"token punctuation\">[</span><span class=\"token string\">'Text'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">apply</span><span class=\"token punctuation\">(</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre>    <span class=\"token keyword\">lambda</span> x<span class=\"token punctuation\">:</span> <span class=\"token string\">\" \"</span><span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>w <span class=\"token keyword\">for</span> w <span class=\"token keyword\">in</span> <span class=\"token builtin\">list</span><span class=\"token punctuation\">(</span>jb<span class=\"token punctuation\">.</span>cut<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">if</span> w <span class=\"token keyword\">not</span> <span class=\"token keyword\">in</span> stop_words<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre>file_txt_test<span class=\"token punctuation\">[</span><span class=\"token string\">'Pre_Text'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> file_txt_test<span class=\"token punctuation\">[</span><span class=\"token string\">'Text'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">apply</span><span class=\"token punctuation\">(</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre>    <span class=\"token keyword\">lambda</span> x<span class=\"token punctuation\">:</span> <span class=\"token string\">\" \"</span><span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>w <span class=\"token keyword\">for</span> w <span class=\"token keyword\">in</span> <span class=\"token builtin\">list</span><span class=\"token punctuation\">(</span>jb<span class=\"token punctuation\">.</span>cut<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">if</span> w <span class=\"token keyword\">not</span> <span class=\"token keyword\">in</span> stop_words<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"12\"></td><td><pre></pre></td></tr><tr><td data-num=\"13\"></td><td><pre><span class=\"token comment\">#   2.3、对训练集切词后的词语进行对整数的映射</span></pre></td></tr><tr><td data-num=\"14\"></td><td><pre><span class=\"token comment\">#       * 先从训练集中找到最长句子的词长度</span></pre></td></tr><tr><td data-num=\"15\"></td><td><pre>max_length <span class=\"token operator\">=</span> <span class=\"token builtin\">max</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>s<span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span><span class=\"token string\">' '</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> s <span class=\"token keyword\">in</span> file_txt_train<span class=\"token punctuation\">[</span><span class=\"token string\">'Pre_Text'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"16\"></td><td><pre><span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>max_length<span class=\"token punctuation\">)</span>  <span class=\"token comment\"># max_length 会随着训练集的不同而改变</span></pre></td></tr><tr><td data-num=\"17\"></td><td><pre></pre></td></tr><tr><td data-num=\"18\"></td><td><pre></pre></td></tr><tr><td data-num=\"19\"></td><td><pre><span class=\"token comment\">#       * 获取分词器（只是用它做标记化处理）</span></pre></td></tr><tr><td data-num=\"20\"></td><td><pre><span class=\"token keyword\">def</span> <span class=\"token function\">create_tokenizer</span><span class=\"token punctuation\">(</span>lines<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"21\"></td><td><pre>    tokenizer <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>preprocessing<span class=\"token punctuation\">.</span>text<span class=\"token punctuation\">.</span>Tokenizer<span class=\"token punctuation\">(</span>oov_token<span class=\"token operator\">=</span><span class=\"token string\">'&lt;UNK>'</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 多加一个未知词</span></pre></td></tr><tr><td data-num=\"22\"></td><td><pre>    tokenizer<span class=\"token punctuation\">.</span>fit_on_texts<span class=\"token punctuation\">(</span>lines<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"23\"></td><td><pre>    <span class=\"token keyword\">return</span> tokenizer</pre></td></tr><tr><td data-num=\"24\"></td><td><pre></pre></td></tr><tr><td data-num=\"25\"></td><td><pre></pre></td></tr><tr><td data-num=\"26\"></td><td><pre>tokenizer <span class=\"token operator\">=</span> create_tokenizer<span class=\"token punctuation\">(</span>file_txt_train<span class=\"token punctuation\">[</span><span class=\"token string\">'Pre_Text'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"27\"></td><td><pre></pre></td></tr><tr><td data-num=\"28\"></td><td><pre></pre></td></tr><tr><td data-num=\"29\"></td><td><pre><span class=\"token comment\">#       * 使用 tokenizer.text_to_sequences () 函数来获取词语 - 整数编码</span></pre></td></tr><tr><td data-num=\"30\"></td><td><pre><span class=\"token comment\">#       * 使用 pad_sequences 函数来为长度不够的文本进行填 0 操作，使所有文本长度一致</span></pre></td></tr><tr><td data-num=\"31\"></td><td><pre><span class=\"token comment\">#       * 进行词语 - 整数映射</span></pre></td></tr><tr><td data-num=\"32\"></td><td><pre><span class=\"token keyword\">def</span> <span class=\"token function\">encode_docs</span><span class=\"token punctuation\">(</span>tokenizer<span class=\"token punctuation\">,</span> max_length<span class=\"token punctuation\">,</span> docs<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"33\"></td><td><pre>    encoded <span class=\"token operator\">=</span> tokenizer<span class=\"token punctuation\">.</span>texts_to_sequences<span class=\"token punctuation\">(</span>docs<span class=\"token punctuation\">)</span>  <span class=\"token comment\">#词语 - 整数映射</span></pre></td></tr><tr><td data-num=\"34\"></td><td><pre>    padded <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>utils<span class=\"token punctuation\">.</span>pad_sequences<span class=\"token punctuation\">(</span>encoded<span class=\"token punctuation\">,</span> maxlen<span class=\"token operator\">=</span>max_length<span class=\"token punctuation\">,</span> padding<span class=\"token operator\">=</span><span class=\"token string\">'post'</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 在结尾处补 0</span></pre></td></tr><tr><td data-num=\"35\"></td><td><pre>    <span class=\"token keyword\">return</span> padded</pre></td></tr><tr><td data-num=\"36\"></td><td><pre></pre></td></tr><tr><td data-num=\"37\"></td><td><pre></pre></td></tr><tr><td data-num=\"38\"></td><td><pre><span class=\"token comment\">#       * 转化为对应特征值和目标值的张量</span></pre></td></tr><tr><td data-num=\"39\"></td><td><pre>X_train <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>constant<span class=\"token punctuation\">(</span>encode_docs<span class=\"token punctuation\">(</span>tokenizer<span class=\"token punctuation\">,</span> max_length<span class=\"token punctuation\">,</span> file_txt_train<span class=\"token punctuation\">[</span><span class=\"token string\">'Pre_Text'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>tolist<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"40\"></td><td><pre>X_test <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>constant<span class=\"token punctuation\">(</span>encode_docs<span class=\"token punctuation\">(</span>tokenizer<span class=\"token punctuation\">,</span> max_length<span class=\"token punctuation\">,</span> file_txt_test<span class=\"token punctuation\">[</span><span class=\"token string\">'Pre_Text'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>tolist<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"41\"></td><td><pre>y_train <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>constant<span class=\"token punctuation\">(</span>file_txt_train<span class=\"token punctuation\">[</span><span class=\"token string\">'Label'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"42\"></td><td><pre>y_test <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>constant<span class=\"token punctuation\">(</span>file_txt_test<span class=\"token punctuation\">[</span><span class=\"token string\">'Label'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"43\"></td><td><pre><span class=\"token comment\">#       * 注意：5 分类  不指定 num_class 时，num_class 的默认值是标签中最大数 + 1</span></pre></td></tr><tr><td data-num=\"44\"></td><td><pre>Y_train <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>constant<span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>utils<span class=\"token punctuation\">.</span>to_categorical<span class=\"token punctuation\">(</span>y_train<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"45\"></td><td><pre>Y_test <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>constant<span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>utils<span class=\"token punctuation\">.</span>to_categorical<span class=\"token punctuation\">(</span>y_test<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure></li>\n<li>\n<p>接着，开始构建模型。<br />\n针对本题，我构建的模型有 <code>一层嵌入层</code> ， <code>两组卷积层</code> 、 <code>池化层</code> 和 <code>Dropout层</code> ， <code>一层flatten层</code> ， <code>两组全连接层</code> 。</p>\n<blockquote>\n<p>1、<strong>嵌入层</strong>：将处理好的词向量输入模型中<br />\n 2、<strong>卷积层、池化层</strong>和<strong> Dropout 层</strong>：卷积层，对词向量进行卷积，采用 3 核进行卷积，第一组选用了 32 个卷积核，以 relu 作为激活函数，第二组选用了 64 个卷积核。卷积层后紧接一层是最大池化层，后接一层 Dropout 层，随机使一定比例的神经元失活，提高模型的泛化能力。<br />\n3、<strong>flatten 层</strong>，将多维的数据一维化，作为卷积层和全连接层的过渡。<br />\n4、<strong>两组全连接层</strong>：作为分类器进行分类，后一个全连接层采用 softmax 函数，转化为 1*6 的张量（由于我先将标签使用了 to_categorical 方法转化，num_class 的默认值是标签中最大数 + 1），所以实现了 5 分类模型</p>\n</blockquote>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\"># 3、构建神经网络模型</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token comment\">#   获取输入维度，即词典数</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>input_dim <span class=\"token operator\">=</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>tokenizer<span class=\"token punctuation\">.</span>word_index<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre></pre></td></tr><tr><td data-num=\"5\"></td><td><pre></pre></td></tr><tr><td data-num=\"6\"></td><td><pre><span class=\"token comment\">#   构建模型</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre><span class=\"token keyword\">def</span> <span class=\"token function\">define_model</span><span class=\"token punctuation\">(</span>input_dim<span class=\"token punctuation\">,</span> max_length<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre>    model <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>Sequential<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre>    <span class=\"token comment\"># 构建一个嵌入层</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre>    model<span class=\"token punctuation\">.</span>add<span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Embedding<span class=\"token punctuation\">(</span>input_dim<span class=\"token operator\">=</span>input_dim<span class=\"token punctuation\">,</span> output_dim<span class=\"token operator\">=</span><span class=\"token number\">128</span><span class=\"token punctuation\">,</span> input_length<span class=\"token operator\">=</span>max_length<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre>    <span class=\"token comment\"># 构建一组卷积层、池化层和 Dropout 层</span></pre></td></tr><tr><td data-num=\"12\"></td><td><pre>    model<span class=\"token punctuation\">.</span>add<span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Conv1D<span class=\"token punctuation\">(</span>filters<span class=\"token operator\">=</span><span class=\"token number\">32</span><span class=\"token punctuation\">,</span> kernel_size<span class=\"token operator\">=</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span>tf<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>relu<span class=\"token punctuation\">,</span> padding<span class=\"token operator\">=</span><span class=\"token string\">\"same\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"13\"></td><td><pre>    model<span class=\"token punctuation\">.</span>add<span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>MaxPooling1D<span class=\"token punctuation\">(</span>pool_size<span class=\"token operator\">=</span><span class=\"token number\">4</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"14\"></td><td><pre>    model<span class=\"token punctuation\">.</span>add<span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dropout<span class=\"token punctuation\">(</span>rate<span class=\"token operator\">=</span><span class=\"token number\">0.2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"15\"></td><td><pre>    <span class=\"token comment\"># 再构建一组卷积层、池化层和 Dropout 层</span></pre></td></tr><tr><td data-num=\"16\"></td><td><pre>    model<span class=\"token punctuation\">.</span>add<span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Conv1D<span class=\"token punctuation\">(</span>filters<span class=\"token operator\">=</span><span class=\"token number\">64</span><span class=\"token punctuation\">,</span> kernel_size<span class=\"token operator\">=</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span>tf<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>relu<span class=\"token punctuation\">,</span> padding<span class=\"token operator\">=</span><span class=\"token string\">\"same\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"17\"></td><td><pre>    model<span class=\"token punctuation\">.</span>add<span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>MaxPooling1D<span class=\"token punctuation\">(</span>pool_size<span class=\"token operator\">=</span><span class=\"token number\">4</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"18\"></td><td><pre>    model<span class=\"token punctuation\">.</span>add<span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dropout<span class=\"token punctuation\">(</span>rate<span class=\"token operator\">=</span><span class=\"token number\">0.2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"19\"></td><td><pre>    <span class=\"token comment\"># 添加 flatten 层，转为一维张量</span></pre></td></tr><tr><td data-num=\"20\"></td><td><pre>    model<span class=\"token punctuation\">.</span>add<span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Flatten<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"21\"></td><td><pre>    <span class=\"token comment\"># 添加两组全连接层</span></pre></td></tr><tr><td data-num=\"22\"></td><td><pre>    model<span class=\"token punctuation\">.</span>add<span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">128</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span>tf<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>relu<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"23\"></td><td><pre>    model<span class=\"token punctuation\">.</span>add<span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">6</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span>tf<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>softmax<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"24\"></td><td><pre>    <span class=\"token comment\"># 配置训练方法</span></pre></td></tr><tr><td data-num=\"25\"></td><td><pre>    model<span class=\"token punctuation\">.</span><span class=\"token builtin\">compile</span><span class=\"token punctuation\">(</span>optimizer<span class=\"token operator\">=</span><span class=\"token string\">'adam'</span><span class=\"token punctuation\">,</span> loss<span class=\"token operator\">=</span><span class=\"token string\">\"categorical_crossentropy\"</span><span class=\"token punctuation\">,</span> metrics<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">\"accuracy\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"26\"></td><td><pre>    <span class=\"token keyword\">return</span> model</pre></td></tr></table></figure><p>模型架构<img data-src=\"https://cdn.statically.io/gh/AliceWantToBackUw/blog-img@main/PicGo/202301291617061.png\" alt=\"image-20230129161720966\" /></p>\n</li>\n<li>\n<p>然后，进行模型训练，保存模型，获取日志信息，以便画图。<br />\n<strong>注意：<strong>模型训练时，先划分 <code>20%</code>  作为</strong>验证集</strong>，用以查看模型的泛化能力</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\"># 4、进行模型训练</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token keyword\">def</span> <span class=\"token function\">model_train</span><span class=\"token punctuation\">(</span>x_train<span class=\"token punctuation\">,</span> y_train<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>    model <span class=\"token operator\">=</span> define_model<span class=\"token punctuation\">(</span>input_dim<span class=\"token punctuation\">,</span> max_length<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>    <span class=\"token comment\"># 训练，并获取训练的日志</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>    history <span class=\"token operator\">=</span> model<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>x_train<span class=\"token punctuation\">,</span> y_train<span class=\"token punctuation\">,</span> batch_size<span class=\"token operator\">=</span><span class=\"token number\">32</span><span class=\"token punctuation\">,</span> epochs<span class=\"token operator\">=</span><span class=\"token number\">100</span><span class=\"token punctuation\">,</span> validation_split<span class=\"token operator\">=</span><span class=\"token number\">0.2</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>                        shuffle<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 再次划分 0.2 为验证集，不参与模型构建</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>    <span class=\"token comment\"># 保存模型</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre>    model<span class=\"token punctuation\">.</span>save<span class=\"token punctuation\">(</span><span class=\"token string\">'temp_word_train.h5'</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre>    <span class=\"token keyword\">return</span> history</pre></td></tr><tr><td data-num=\"10\"></td><td><pre></pre></td></tr><tr><td data-num=\"11\"></td><td><pre></pre></td></tr><tr><td data-num=\"12\"></td><td><pre>history <span class=\"token operator\">=</span> model_train<span class=\"token punctuation\">(</span>X_train<span class=\"token punctuation\">,</span> Y_train<span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 获取日志</span></pre></td></tr></table></figure></li>\n<li>\n<p>接着，加载模型，进行模型评估</p>\n</li>\n</ul>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\"># 5、加载模型进行预测</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token comment\">#   5.1、加载模型</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token comment\"># temp_model = tf.keras.models.load_model (\"./ 验证集 0.90 准确率的模型.h5\")</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>temp_model <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>models<span class=\"token punctuation\">.</span>load_model<span class=\"token punctuation\">(</span><span class=\"token string\">\"./temp_word_train.h5\"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre></pre></td></tr><tr><td data-num=\"6\"></td><td><pre><span class=\"token comment\"># 6、评估模型</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre><span class=\"token comment\">#   使用测试集来评估模型的准确率</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre>evaluate <span class=\"token operator\">=</span> temp_model<span class=\"token punctuation\">.</span>evaluate<span class=\"token punctuation\">(</span>X_test<span class=\"token punctuation\">,</span> Y_test<span class=\"token punctuation\">,</span> verbose<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre><span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>evaluate<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre><span class=\"token comment\">#   * 查看测试集中没有预测中的数据集</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre>pre_label <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>argmax<span class=\"token punctuation\">(</span>temp_model<span class=\"token punctuation\">.</span>predict<span class=\"token punctuation\">(</span>X_test<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> axis<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"12\"></td><td><pre>result <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>DataFrame<span class=\"token punctuation\">(</span><span class=\"token punctuation\">&#123;</span><span class=\"token string\">\"真实标签\"</span><span class=\"token punctuation\">:</span> y_test<span class=\"token punctuation\">,</span> <span class=\"token string\">\"预测标签\"</span><span class=\"token punctuation\">:</span> pre_label<span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"13\"></td><td><pre>result<span class=\"token punctuation\">[</span>result<span class=\"token punctuation\">[</span><span class=\"token string\">\"真实标签\"</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">!=</span> result<span class=\"token punctuation\">[</span><span class=\"token string\">\"预测标签\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span></pre></td></tr></table></figure><ul>\n<li>\n<p>最后，通过画图来展示模型质量<br />\n根据模型对<strong>训练集</strong>的训练结果，来绘制 <code>loss值</code> 与 <code>迭代轮数</code> 的关系， <code>准确率</code> 与 <code>迭代轮数</code> 的关系</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\"># 7、绘制分类图</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token comment\">#   7.1、获取日志信息</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>plt<span class=\"token punctuation\">.</span>rcParams<span class=\"token punctuation\">[</span><span class=\"token string\">\"font.sans-serif\"</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"SimHei\"</span><span class=\"token punctuation\">]</span>  <span class=\"token comment\"># 显示中文标签</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>plt<span class=\"token punctuation\">.</span>rcParams<span class=\"token punctuation\">[</span><span class=\"token string\">'axes.unicode_minus'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token boolean\">False</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>loss <span class=\"token operator\">=</span> history<span class=\"token punctuation\">.</span>history<span class=\"token punctuation\">[</span><span class=\"token string\">\"loss\"</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>val_loss <span class=\"token operator\">=</span> history<span class=\"token punctuation\">.</span>history<span class=\"token punctuation\">[</span><span class=\"token string\">\"val_loss\"</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>acc <span class=\"token operator\">=</span> history<span class=\"token punctuation\">.</span>history<span class=\"token punctuation\">[</span><span class=\"token string\">\"accuracy\"</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre>val_acc <span class=\"token operator\">=</span> history<span class=\"token punctuation\">.</span>history<span class=\"token punctuation\">[</span><span class=\"token string\">\"val_accuracy\"</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre></pre></td></tr><tr><td data-num=\"10\"></td><td><pre><span class=\"token comment\">#   7.2、绘制训练和验证集的损失值和迭代伦数、精确率和迭代轮数的图像</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre>plt<span class=\"token punctuation\">.</span>figure<span class=\"token punctuation\">(</span>figsize<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">15</span><span class=\"token punctuation\">,</span> <span class=\"token number\">10</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"12\"></td><td><pre></pre></td></tr><tr><td data-num=\"13\"></td><td><pre>plt<span class=\"token punctuation\">.</span>subplot<span class=\"token punctuation\">(</span><span class=\"token number\">221</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"14\"></td><td><pre>plt<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span>loss<span class=\"token punctuation\">,</span>color<span class=\"token operator\">=</span><span class=\"token string\">\"blue\"</span><span class=\"token punctuation\">,</span>label<span class=\"token operator\">=</span><span class=\"token string\">\"train\"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"15\"></td><td><pre>plt<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span>val_loss<span class=\"token punctuation\">,</span>color<span class=\"token operator\">=</span><span class=\"token string\">\"red\"</span><span class=\"token punctuation\">,</span>label<span class=\"token operator\">=</span><span class=\"token string\">\"test\"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"16\"></td><td><pre>plt<span class=\"token punctuation\">.</span>ylabel<span class=\"token punctuation\">(</span><span class=\"token string\">\"Loss\"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"17\"></td><td><pre>plt<span class=\"token punctuation\">.</span>legend<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"18\"></td><td><pre></pre></td></tr><tr><td data-num=\"19\"></td><td><pre>plt<span class=\"token punctuation\">.</span>subplot<span class=\"token punctuation\">(</span><span class=\"token number\">222</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"20\"></td><td><pre>plt<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span>acc<span class=\"token punctuation\">,</span>color<span class=\"token operator\">=</span><span class=\"token string\">\"blue\"</span><span class=\"token punctuation\">,</span>label<span class=\"token operator\">=</span><span class=\"token string\">\"train\"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"21\"></td><td><pre>plt<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span>val_acc<span class=\"token punctuation\">,</span>color<span class=\"token operator\">=</span><span class=\"token string\">\"red\"</span><span class=\"token punctuation\">,</span>label<span class=\"token operator\">=</span><span class=\"token string\">\"test\"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"22\"></td><td><pre>plt<span class=\"token punctuation\">.</span>ylabel<span class=\"token punctuation\">(</span><span class=\"token string\">\"Accuracy\"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"23\"></td><td><pre>plt<span class=\"token punctuation\">.</span>legend<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"24\"></td><td><pre></pre></td></tr><tr><td data-num=\"25\"></td><td><pre></pre></td></tr><tr><td data-num=\"26\"></td><td><pre>plt<span class=\"token punctuation\">.</span>subplot<span class=\"token punctuation\">(</span><span class=\"token number\">223</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"27\"></td><td><pre>scale_ls <span class=\"token operator\">=</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">6</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"28\"></td><td><pre>index_ls <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token string\">'__label__1'</span><span class=\"token punctuation\">,</span><span class=\"token string\">'__label__2'</span><span class=\"token punctuation\">,</span><span class=\"token string\">'__label__3'</span><span class=\"token punctuation\">,</span><span class=\"token string\">'__label__4'</span><span class=\"token punctuation\">,</span><span class=\"token string\">'__label__5'</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"29\"></td><td><pre>plt<span class=\"token punctuation\">.</span>yticks<span class=\"token punctuation\">(</span>scale_ls<span class=\"token punctuation\">,</span>index_ls<span class=\"token punctuation\">)</span> <span class=\"token comment\">## 可以设置坐标字</span></pre></td></tr><tr><td data-num=\"30\"></td><td><pre>plt<span class=\"token punctuation\">.</span>title<span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"acc: </span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span><span class=\"token builtin\">round</span><span class=\"token punctuation\">(</span>evaluate<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">&#125;</span></span><span class=\"token string\">\"</span></span><span class=\"token punctuation\">,</span> fontsize<span class=\"token operator\">=</span><span class=\"token number\">20</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"31\"></td><td><pre>plt<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span>result<span class=\"token punctuation\">[</span><span class=\"token string\">\"真实标签\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>tolist<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> color<span class=\"token operator\">=</span><span class=\"token string\">\"red\"</span><span class=\"token punctuation\">,</span> marker<span class=\"token operator\">=</span><span class=\"token string\">'o'</span><span class=\"token punctuation\">,</span> label<span class=\"token operator\">=</span><span class=\"token string\">\"真实分类\"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"32\"></td><td><pre>plt<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span>result<span class=\"token punctuation\">[</span><span class=\"token string\">\"预测标签\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>tolist<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> color<span class=\"token operator\">=</span><span class=\"token string\">\"blue\"</span><span class=\"token punctuation\">,</span> marker<span class=\"token operator\">=</span><span class=\"token string\">'.'</span><span class=\"token punctuation\">,</span> label<span class=\"token operator\">=</span><span class=\"token string\">\"预测分类\"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"33\"></td><td><pre>plt<span class=\"token punctuation\">.</span>xlabel<span class=\"token punctuation\">(</span><span class=\"token string\">\"样本\"</span><span class=\"token punctuation\">,</span> fontsize<span class=\"token operator\">=</span><span class=\"token number\">14</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"34\"></td><td><pre>plt<span class=\"token punctuation\">.</span>ylabel<span class=\"token punctuation\">(</span><span class=\"token string\">\"分类\"</span><span class=\"token punctuation\">,</span> fontsize<span class=\"token operator\">=</span><span class=\"token number\">14</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"35\"></td><td><pre></pre></td></tr><tr><td data-num=\"36\"></td><td><pre></pre></td></tr><tr><td data-num=\"37\"></td><td><pre>plt<span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure><p><img data-src=\"https://cdn.statically.io/gh/AliceWantToBackUw/blog-img@main/PicGo/202301291620114.png\" alt=\"image-20230129162035008\" /></p>\n</li>\n</ul>\n<p>​\t<strong>说明：<strong>上面两图中 <code>test集</code> 实际上又从 <code>train集</code> 种随机划分部分出来的作为 <code>valid集</code> ，<strong>只有下面一幅图</strong>才是对 <code>test集</code> 的预测<br />\n​\t从图中可以看出，该模型在</strong>测试集</strong>上的 <code>准确率：0.9</code> ，而且模型在<strong>验证集</strong>上的 <code>准确率稳定在0.88</code> 。还不错。<br />\n​\t而样本在迭代 <code>40次左右</code> ，<strong>验证集</strong>的准确率的 <code>损失函数值</code> 就趋于<strong>稳定</strong>了，当 <code>超过40次</code> 时，还略微有<strong>上升</strong>的趋势。这说明，迭代次数 <code>超过40次</code> ，容易出现过拟合，需要避免。</p>\n<h3 id=\"fasttext\"><a class=\"anchor\" href=\"#fasttext\">#</a> 🔑FastText</h3>\n<blockquote>\n<p><strong>FastText 官方文档：</strong><span class=\"exturl\" data-url=\"aHR0cHM6Ly9mYXN0dGV4dC5jYy9kb2NzL2VuL2F1dG90dW5lLmh0bWw=\">Automatic hyperparameter optimization · fastText</span></p>\n</blockquote>\n<ul>\n<li>\n<p>同样，首先导包</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">import</span> pandas <span class=\"token keyword\">as</span> pd</pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token keyword\">import</span> jieba</pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token keyword\">import</span> random</pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token keyword\">import</span> fasttext</pre></td></tr><tr><td data-num=\"5\"></td><td><pre><span class=\"token keyword\">import</span> matplotlib<span class=\"token punctuation\">.</span>pyplot <span class=\"token keyword\">as</span> plt</pre></td></tr></table></figure></li>\n<li>\n<p>接着，先获取数据，加载停用词</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\"># 1、获取数据</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>df_all_data <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>read_excel<span class=\"token punctuation\">(</span>io<span class=\"token operator\">=</span><span class=\"token string\">\"../src/gastric.xlsx\"</span><span class=\"token punctuation\">,</span> engine<span class=\"token operator\">=</span><span class=\"token string\">\"openpyxl\"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token comment\">#   * 加载停用词</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token keyword\">with</span> <span class=\"token builtin\">open</span><span class=\"token punctuation\">(</span><span class=\"token string\">'../src/stop_words.txt'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'r'</span><span class=\"token punctuation\">,</span> encoding<span class=\"token operator\">=</span><span class=\"token string\">\"utf-8\"</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> f<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>    stop_words <span class=\"token operator\">=</span> <span class=\"token builtin\">list</span><span class=\"token punctuation\">(</span>l<span class=\"token punctuation\">.</span>strip<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> l <span class=\"token keyword\">in</span> f<span class=\"token punctuation\">.</span>readlines<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>stop_words<span class=\"token punctuation\">.</span>extend<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token string\">'\\n'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'（'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'）'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">' '</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 由于停用词中没有 '\\n' 和中文的左右括号和空格，所以单独再加上去</span></pre></td></tr></table></figure></li>\n<li>\n<p>然后，对数据进行预处理，随机打乱，简单划分成训练集、验证集和测试集。</p>\n</li>\n</ul>\n<blockquote>\n<p><code>fastText</code>  对文本输入有要求，需要进行预处理，因为默认前缀是 <code>__label__</code> ，所以要处理成将数据处理成 <code>fasttext</code>  可以处理的格式。如：  <code>__label__1,胃角 小弯 ……</code></p>\n</blockquote>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\"># 2、数据预处理</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token comment\">#   * 将数据处理成 fasttext 可以处理的格式，如：  __label__1, 胃角 小弯 ……</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token keyword\">def</span> <span class=\"token function\">preprocess_data_to_fasttext</span><span class=\"token punctuation\">(</span>pd_data<span class=\"token punctuation\">,</span> sentences<span class=\"token punctuation\">,</span> stopwords<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>    <span class=\"token keyword\">for</span> _<span class=\"token punctuation\">,</span> row <span class=\"token keyword\">in</span> pd_data<span class=\"token punctuation\">.</span>iterrows<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>        temp <span class=\"token operator\">=</span> jieba<span class=\"token punctuation\">.</span>cut<span class=\"token punctuation\">(</span>row<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>        temp <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>k <span class=\"token keyword\">for</span> k <span class=\"token keyword\">in</span> jieba<span class=\"token punctuation\">.</span>lcut<span class=\"token punctuation\">(</span>row<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> cut_all<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">if</span> k <span class=\"token keyword\">not</span> <span class=\"token keyword\">in</span> stopwords<span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>        sentences<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span><span class=\"token string\">'__label__'</span> <span class=\"token operator\">+</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">(</span>row<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> <span class=\"token string\">', '</span> <span class=\"token operator\">+</span> <span class=\"token string\">' '</span><span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span>temp<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 由于 Label 是整形，所以需要改为字符</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre>        <span class=\"token comment\">#         sentences.append ('__label__'+str (row [0])+' '.join (temp)) # 由于 Label 是整形，所以需要改为字符</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre>        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>row<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre></pre></td></tr><tr><td data-num=\"11\"></td><td><pre></pre></td></tr><tr><td data-num=\"12\"></td><td><pre>result_sentences <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>  <span class=\"token comment\"># 存储分词后的所有种类的文本</span></pre></td></tr><tr><td data-num=\"13\"></td><td><pre>preprocess_data_to_fasttext<span class=\"token punctuation\">(</span>df_all_data<span class=\"token punctuation\">,</span> result_sentences<span class=\"token punctuation\">,</span> stop_words<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"14\"></td><td><pre><span class=\"token comment\">#   * 随机打乱数据</span></pre></td></tr><tr><td data-num=\"15\"></td><td><pre>random<span class=\"token punctuation\">.</span>shuffle<span class=\"token punctuation\">(</span>result_sentences<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"16\"></td><td><pre><span class=\"token comment\">#   * 简单划分训练集、验证集和测试集，并将数据保存至 txt 文件</span></pre></td></tr><tr><td data-num=\"17\"></td><td><pre><span class=\"token keyword\">with</span> <span class=\"token builtin\">open</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">file</span><span class=\"token operator\">=</span><span class=\"token string\">\"./fasttext_train.txt\"</span><span class=\"token punctuation\">,</span> mode<span class=\"token operator\">=</span><span class=\"token string\">'w'</span><span class=\"token punctuation\">,</span> encoding<span class=\"token operator\">=</span><span class=\"token string\">\"utf8\"</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> fw<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"18\"></td><td><pre>    <span class=\"token keyword\">for</span> sentence <span class=\"token keyword\">in</span> result_sentences<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token builtin\">int</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>result_sentences<span class=\"token punctuation\">)</span> <span class=\"token operator\">*</span> <span class=\"token number\">.7</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"19\"></td><td><pre>        fw<span class=\"token punctuation\">.</span>write<span class=\"token punctuation\">(</span>sentence <span class=\"token operator\">+</span> <span class=\"token string\">'\\n'</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"20\"></td><td><pre><span class=\"token keyword\">with</span> <span class=\"token builtin\">open</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">file</span><span class=\"token operator\">=</span><span class=\"token string\">\"./fasttext_valid.txt\"</span><span class=\"token punctuation\">,</span> mode<span class=\"token operator\">=</span><span class=\"token string\">'w'</span><span class=\"token punctuation\">,</span> encoding<span class=\"token operator\">=</span><span class=\"token string\">\"utf8\"</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> fw<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"21\"></td><td><pre>    <span class=\"token keyword\">for</span> sentence <span class=\"token keyword\">in</span> result_sentences<span class=\"token punctuation\">[</span><span class=\"token builtin\">int</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>result_sentences<span class=\"token punctuation\">)</span> <span class=\"token operator\">*</span> <span class=\"token number\">.7</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span><span class=\"token builtin\">int</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>result_sentences<span class=\"token punctuation\">)</span> <span class=\"token operator\">*</span> <span class=\"token number\">.9</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"22\"></td><td><pre>        fw<span class=\"token punctuation\">.</span>write<span class=\"token punctuation\">(</span>sentence <span class=\"token operator\">+</span> <span class=\"token string\">'\\n'</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"23\"></td><td><pre><span class=\"token keyword\">with</span> <span class=\"token builtin\">open</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">file</span><span class=\"token operator\">=</span><span class=\"token string\">\"./fasttext_test.txt\"</span><span class=\"token punctuation\">,</span> mode<span class=\"token operator\">=</span><span class=\"token string\">'w'</span><span class=\"token punctuation\">,</span> encoding<span class=\"token operator\">=</span><span class=\"token string\">\"utf8\"</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> fw<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"24\"></td><td><pre>    <span class=\"token keyword\">for</span> sentence <span class=\"token keyword\">in</span> result_sentences<span class=\"token punctuation\">[</span><span class=\"token builtin\">int</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>result_sentences<span class=\"token punctuation\">)</span> <span class=\"token operator\">*</span> <span class=\"token number\">.9</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"25\"></td><td><pre>        fw<span class=\"token punctuation\">.</span>write<span class=\"token punctuation\">(</span>sentence <span class=\"token operator\">+</span> <span class=\"token string\">'\\n'</span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure><ul>\n<li>接着，构建 <code>FastText</code>  模型，查阅<span class=\"exturl\" data-url=\"aHR0cHM6Ly9mYXN0dGV4dC5jYy9kb2NzL2VuL2F1dG90dW5lLmh0bWw=\">官网</span>，发现可以 FastText 可以在指定时间内，自动调优寻找最佳 <code>f1分数</code> ，果断用它<br />\n<img data-src=\"https://cdn.statically.io/gh/AliceWantToBackUw/blog-img@main/PicGo/202301291631524.png\" alt=\"image-20230129163129440\" /><br />\n 所以，以 train 集建立起 FastText 模型，设置训练时间为 60s</li>\n</ul>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\"># 3、通过 fasttext 自动实现超参数优化，获取模型</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>ft_model <span class=\"token operator\">=</span> fasttext<span class=\"token punctuation\">.</span>train_supervised<span class=\"token punctuation\">(</span><span class=\"token builtin\">input</span><span class=\"token operator\">=</span><span class=\"token string\">'./fasttext_train.txt'</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>                                     autotuneValidationFile<span class=\"token operator\">=</span><span class=\"token string\">'./fasttext_valid.txt'</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>                                     autotuneDuration<span class=\"token operator\">=</span><span class=\"token number\">60</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>ft_model<span class=\"token punctuation\">.</span>save_model<span class=\"token punctuation\">(</span><span class=\"token string\">\"./fasttext_model.bin\"</span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure><ul>\n<li>\n<p>其次，加载模型（加载的模型，我选了另一个最好的，可调），进行模型评估和预测，并画图展示</p>\n<blockquote>\n<p><strong>注意：<strong>针对</strong>多分类</strong>问题，直接查看 <code>fastText</code>  自带的<strong>精确率</strong>和<strong>召回率</strong>是<strong>一样</strong>的，都是<strong>准确率</strong>。<br />\n<strong>详细请见：</strong><span class=\"exturl\" data-url=\"aHR0cHM6Ly93d3cuemhpaHUuY29tL3F1ZXN0aW9uLzQxNDgyNDk2OQ==\">为什么多分类计算出来的精确率 准确率 召回率 f1-score 值都一样？ - 知乎 (zhihu.com)</span></p>\n</blockquote>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\"># 4、加载模型</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>fasttext<span class=\"token punctuation\">.</span>FastText<span class=\"token punctuation\">.</span>eprint <span class=\"token operator\">=</span> <span class=\"token keyword\">lambda</span> x<span class=\"token punctuation\">:</span> <span class=\"token boolean\">None</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>ft_model <span class=\"token operator\">=</span> fasttext<span class=\"token punctuation\">.</span>load_model<span class=\"token punctuation\">(</span><span class=\"token string\">\"./fasttext_best_model.bin\"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre></pre></td></tr><tr><td data-num=\"5\"></td><td><pre><span class=\"token comment\"># 5、模型评估以及预测</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre></pre></td></tr><tr><td data-num=\"7\"></td><td><pre><span class=\"token keyword\">def</span> <span class=\"token function\">my_test</span><span class=\"token punctuation\">(</span>filepath<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre>    <span class=\"token keyword\">global</span> ft_model<span class=\"token punctuation\">,</span>acc<span class=\"token punctuation\">,</span>number</pre></td></tr><tr><td data-num=\"9\"></td><td><pre>    <span class=\"token triple-quoted-string string\">\"\"\"</pre></td></tr><tr><td data-num=\"10\"></td><td><pre>    :param filepath: 需要测试的文件</pre></td></tr><tr><td data-num=\"11\"></td><td><pre>    :return:  label_list: 真实分类  labels_predict: 预处理好的分类</pre></td></tr><tr><td data-num=\"12\"></td><td><pre>    \"\"\"</span></pre></td></tr><tr><td data-num=\"13\"></td><td><pre>    <span class=\"token comment\"># 由于是多分类（该题每篇文本，仅仅属于某种分类，可以该文本仅有成唯一标签，所以 k=1）</span></pre></td></tr><tr><td data-num=\"14\"></td><td><pre>    <span class=\"token comment\"># 直接求整体的精确率和召回率都相当是求 预测正确的分类个数 / 总共的个数</span></pre></td></tr><tr><td data-num=\"15\"></td><td><pre>    result <span class=\"token operator\">=</span> ft_model<span class=\"token punctuation\">.</span>test<span class=\"token punctuation\">(</span>filepath<span class=\"token punctuation\">,</span> k<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"16\"></td><td><pre>    <span class=\"token comment\"># 所以准确率 = 精确率 = 召回率</span></pre></td></tr><tr><td data-num=\"17\"></td><td><pre>    acc <span class=\"token operator\">=</span> result<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"18\"></td><td><pre>    number <span class=\"token operator\">=</span> result<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"19\"></td><td><pre>    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'样本数量:'</span><span class=\"token punctuation\">,</span> result<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"20\"></td><td><pre>    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'准确率:'</span><span class=\"token punctuation\">,</span> acc<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"21\"></td><td><pre>    content_list <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"22\"></td><td><pre>    label_list <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"23\"></td><td><pre>    <span class=\"token keyword\">with</span> <span class=\"token builtin\">open</span><span class=\"token punctuation\">(</span>filepath<span class=\"token punctuation\">,</span> <span class=\"token string\">'r'</span><span class=\"token punctuation\">,</span> encoding<span class=\"token operator\">=</span><span class=\"token string\">\"utf-8\"</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> fr<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"24\"></td><td><pre>        <span class=\"token keyword\">for</span> line <span class=\"token keyword\">in</span> fr<span class=\"token punctuation\">.</span>readlines<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"25\"></td><td><pre>            content_list<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>line<span class=\"token punctuation\">.</span>strip<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span><span class=\"token string\">\",\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"26\"></td><td><pre>            label_list<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>line<span class=\"token punctuation\">.</span>strip<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span><span class=\"token string\">\",\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"27\"></td><td><pre>    <span class=\"token comment\"># * 预处理一下预测的标签标签值 使之与从测试集读取出来的 label 格式一致</span></pre></td></tr><tr><td data-num=\"28\"></td><td><pre>    labels_predict <span class=\"token operator\">=</span> ft_model<span class=\"token punctuation\">.</span>predict<span class=\"token punctuation\">(</span>content_list<span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"29\"></td><td><pre>    labels_predict <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span> <span class=\"token keyword\">for</span> ii <span class=\"token keyword\">in</span> labels_predict <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> ii<span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"30\"></td><td><pre>    <span class=\"token keyword\">return</span> label_list<span class=\"token punctuation\">,</span>labels_predict</pre></td></tr><tr><td data-num=\"31\"></td><td><pre></pre></td></tr><tr><td data-num=\"32\"></td><td><pre><span class=\"token comment\"># 5.2、绘图</span></pre></td></tr><tr><td data-num=\"33\"></td><td><pre>plt<span class=\"token punctuation\">.</span>rcParams<span class=\"token punctuation\">[</span><span class=\"token string\">\"font.sans-serif\"</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"SimHei\"</span><span class=\"token punctuation\">]</span>  <span class=\"token comment\"># 显示中文标签</span></pre></td></tr><tr><td data-num=\"34\"></td><td><pre>plt<span class=\"token punctuation\">.</span>rcParams<span class=\"token punctuation\">[</span><span class=\"token string\">'axes.unicode_minus'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token boolean\">False</span></pre></td></tr><tr><td data-num=\"35\"></td><td><pre>plt<span class=\"token punctuation\">.</span>figure<span class=\"token punctuation\">(</span>figsize<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">12</span><span class=\"token punctuation\">,</span> <span class=\"token number\">10</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"36\"></td><td><pre>scale_ls <span class=\"token operator\">=</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token number\">5</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"37\"></td><td><pre>index_ls <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token string\">'__label__1'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'__label__2'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'__label__3'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'__label__4'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'__label__5'</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"38\"></td><td><pre></pre></td></tr><tr><td data-num=\"39\"></td><td><pre></pre></td></tr><tr><td data-num=\"40\"></td><td><pre>plt<span class=\"token punctuation\">.</span>subplot<span class=\"token punctuation\">(</span><span class=\"token number\">311</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"41\"></td><td><pre>plt<span class=\"token punctuation\">.</span>yticks<span class=\"token punctuation\">(</span>scale_ls<span class=\"token punctuation\">,</span> index_ls<span class=\"token punctuation\">)</span>  <span class=\"token comment\">## 可以设置坐标字</span></pre></td></tr><tr><td data-num=\"42\"></td><td><pre>filepath <span class=\"token operator\">=</span> <span class=\"token string\">\"./fasttext_train.txt\"</span></pre></td></tr><tr><td data-num=\"43\"></td><td><pre>label_list<span class=\"token punctuation\">,</span> labels_predict<span class=\"token operator\">=</span> my_test<span class=\"token punctuation\">(</span>filepath<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"44\"></td><td><pre>plt<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span>label_list<span class=\"token punctuation\">,</span> color<span class=\"token operator\">=</span><span class=\"token string\">\"red\"</span><span class=\"token punctuation\">,</span> marker<span class=\"token operator\">=</span><span class=\"token string\">'o'</span><span class=\"token punctuation\">,</span> label<span class=\"token operator\">=</span><span class=\"token string\">\"真实分类\"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"45\"></td><td><pre>plt<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span>labels_predict<span class=\"token punctuation\">,</span> color<span class=\"token operator\">=</span><span class=\"token string\">\"blue\"</span><span class=\"token punctuation\">,</span> marker<span class=\"token operator\">=</span><span class=\"token string\">'.'</span><span class=\"token punctuation\">,</span> label<span class=\"token operator\">=</span><span class=\"token string\">\"预测分类\"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"46\"></td><td><pre>plt<span class=\"token punctuation\">.</span>xlabel<span class=\"token punctuation\">(</span><span class=\"token string\">\"样本\"</span><span class=\"token punctuation\">,</span> fontsize<span class=\"token operator\">=</span><span class=\"token number\">14</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"47\"></td><td><pre>plt<span class=\"token punctuation\">.</span>ylabel<span class=\"token punctuation\">(</span><span class=\"token string\">\"分类\"</span><span class=\"token punctuation\">,</span> fontsize<span class=\"token operator\">=</span><span class=\"token number\">14</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"48\"></td><td><pre>plt<span class=\"token punctuation\">.</span>title<span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"</span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span>filepath<span class=\"token punctuation\">[</span><span class=\"token number\">2</span><span class=\"token punctuation\">:</span><span class=\"token format-spec\">-4]</span><span class=\"token punctuation\">&#125;</span></span><span class=\"token string\">   number:</span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span>number<span class=\"token punctuation\">&#125;</span></span><span class=\"token string\">   acc: </span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span><span class=\"token builtin\">round</span><span class=\"token punctuation\">(</span>acc<span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">&#125;</span></span><span class=\"token string\">\"</span></span><span class=\"token punctuation\">,</span> fontsize<span class=\"token operator\">=</span><span class=\"token number\">20</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"49\"></td><td><pre></pre></td></tr><tr><td data-num=\"50\"></td><td><pre>plt<span class=\"token punctuation\">.</span>subplot<span class=\"token punctuation\">(</span><span class=\"token number\">312</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"51\"></td><td><pre>plt<span class=\"token punctuation\">.</span>yticks<span class=\"token punctuation\">(</span>scale_ls<span class=\"token punctuation\">,</span> index_ls<span class=\"token punctuation\">)</span>  <span class=\"token comment\">## 可以设置坐标字</span></pre></td></tr><tr><td data-num=\"52\"></td><td><pre>filepath <span class=\"token operator\">=</span> <span class=\"token string\">\"./fasttext_valid.txt\"</span></pre></td></tr><tr><td data-num=\"53\"></td><td><pre>label_list<span class=\"token punctuation\">,</span> labels_predict<span class=\"token operator\">=</span> my_test<span class=\"token punctuation\">(</span>filepath<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"54\"></td><td><pre>plt<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span>label_list<span class=\"token punctuation\">,</span> color<span class=\"token operator\">=</span><span class=\"token string\">\"red\"</span><span class=\"token punctuation\">,</span> marker<span class=\"token operator\">=</span><span class=\"token string\">'o'</span><span class=\"token punctuation\">,</span> label<span class=\"token operator\">=</span><span class=\"token string\">\"真实分类\"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"55\"></td><td><pre>plt<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span>labels_predict<span class=\"token punctuation\">,</span> color<span class=\"token operator\">=</span><span class=\"token string\">\"blue\"</span><span class=\"token punctuation\">,</span> marker<span class=\"token operator\">=</span><span class=\"token string\">'.'</span><span class=\"token punctuation\">,</span> label<span class=\"token operator\">=</span><span class=\"token string\">\"预测分类\"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"56\"></td><td><pre>plt<span class=\"token punctuation\">.</span>xlabel<span class=\"token punctuation\">(</span><span class=\"token string\">\"样本\"</span><span class=\"token punctuation\">,</span> fontsize<span class=\"token operator\">=</span><span class=\"token number\">14</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"57\"></td><td><pre>plt<span class=\"token punctuation\">.</span>ylabel<span class=\"token punctuation\">(</span><span class=\"token string\">\"分类\"</span><span class=\"token punctuation\">,</span> fontsize<span class=\"token operator\">=</span><span class=\"token number\">14</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"58\"></td><td><pre>plt<span class=\"token punctuation\">.</span>title<span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"</span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span>filepath<span class=\"token punctuation\">[</span><span class=\"token number\">2</span><span class=\"token punctuation\">:</span><span class=\"token format-spec\">-4]</span><span class=\"token punctuation\">&#125;</span></span><span class=\"token string\">   number:</span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span>number<span class=\"token punctuation\">&#125;</span></span><span class=\"token string\">   acc: </span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span><span class=\"token builtin\">round</span><span class=\"token punctuation\">(</span>acc<span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">&#125;</span></span><span class=\"token string\">\"</span></span><span class=\"token punctuation\">,</span> fontsize<span class=\"token operator\">=</span><span class=\"token number\">20</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"59\"></td><td><pre></pre></td></tr><tr><td data-num=\"60\"></td><td><pre>plt<span class=\"token punctuation\">.</span>subplot<span class=\"token punctuation\">(</span><span class=\"token number\">313</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"61\"></td><td><pre>plt<span class=\"token punctuation\">.</span>yticks<span class=\"token punctuation\">(</span>scale_ls<span class=\"token punctuation\">,</span> index_ls<span class=\"token punctuation\">)</span>  <span class=\"token comment\">## 可以设置坐标字</span></pre></td></tr><tr><td data-num=\"62\"></td><td><pre>filepath <span class=\"token operator\">=</span> <span class=\"token string\">\"./fasttext_test.txt\"</span></pre></td></tr><tr><td data-num=\"63\"></td><td><pre>label_list<span class=\"token punctuation\">,</span> labels_predict<span class=\"token operator\">=</span> my_test<span class=\"token punctuation\">(</span>filepath<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"64\"></td><td><pre>plt<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span>label_list<span class=\"token punctuation\">,</span> color<span class=\"token operator\">=</span><span class=\"token string\">\"red\"</span><span class=\"token punctuation\">,</span> marker<span class=\"token operator\">=</span><span class=\"token string\">'o'</span><span class=\"token punctuation\">,</span> label<span class=\"token operator\">=</span><span class=\"token string\">\"真实分类\"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"65\"></td><td><pre>plt<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span>labels_predict<span class=\"token punctuation\">,</span> color<span class=\"token operator\">=</span><span class=\"token string\">\"blue\"</span><span class=\"token punctuation\">,</span> marker<span class=\"token operator\">=</span><span class=\"token string\">'.'</span><span class=\"token punctuation\">,</span> label<span class=\"token operator\">=</span><span class=\"token string\">\"预测分类\"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"66\"></td><td><pre>plt<span class=\"token punctuation\">.</span>xlabel<span class=\"token punctuation\">(</span><span class=\"token string\">\"样本\"</span><span class=\"token punctuation\">,</span> fontsize<span class=\"token operator\">=</span><span class=\"token number\">14</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"67\"></td><td><pre>plt<span class=\"token punctuation\">.</span>ylabel<span class=\"token punctuation\">(</span><span class=\"token string\">\"分类\"</span><span class=\"token punctuation\">,</span> fontsize<span class=\"token operator\">=</span><span class=\"token number\">14</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"68\"></td><td><pre>plt<span class=\"token punctuation\">.</span>title<span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"</span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span>filepath<span class=\"token punctuation\">[</span><span class=\"token number\">2</span><span class=\"token punctuation\">:</span><span class=\"token format-spec\">-4]</span><span class=\"token punctuation\">&#125;</span></span><span class=\"token string\">   number:</span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span>number<span class=\"token punctuation\">&#125;</span></span><span class=\"token string\">   acc: </span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span><span class=\"token builtin\">round</span><span class=\"token punctuation\">(</span>acc<span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">&#125;</span></span><span class=\"token string\">\"</span></span><span class=\"token punctuation\">,</span> fontsize<span class=\"token operator\">=</span><span class=\"token number\">20</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"69\"></td><td><pre></pre></td></tr><tr><td data-num=\"70\"></td><td><pre>plt<span class=\"token punctuation\">.</span>tight_layout<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># 解决标题重叠</span></pre></td></tr><tr><td data-num=\"71\"></td><td><pre>plt<span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure><p><img data-src=\"https://cdn.statically.io/gh/AliceWantToBackUw/blog-img@main/PicGo/202301291634671.png\" alt=\"image-20230129163445544\" /></p>\n</li>\n</ul>\n<p>​\t从图可以看出， <code>fasttext</code>  强者，竟如此恐怖如斯。在<strong>训练集</strong>上的 <code>准确率达到0.96</code> ，在<strong>验证集</strong>上的 <code>准确率达到0.94</code> ，在<strong>测试集</strong>上的 <code>准确率达到1</code> 。（当然，可能数据量过少了）而且，最重要的是，他还稳得很，构建很多次模型，测试集上得准确率基本保持在 <code>0.9以上</code> 。</p>\n<h2 id=\"总结\"><a class=\"anchor\" href=\"#总结\">#</a> 🎒总结</h2>\n<p>​\t可能是自己构建的 <code>textCNN</code>  模型中的词向量，单纯只是一个简单的整数映射，整数之间毫无关系，所以卷积效果不佳；也可能是由于数据量太少，准确率不稳定。<br />\n​\t总之，还是 <code>fasttext</code>  更胜一筹。</p>\n",
            "tags": [
                "NLP",
                "文本分类",
                "合工大",
                "深度学习"
            ]
        }
    ]
}